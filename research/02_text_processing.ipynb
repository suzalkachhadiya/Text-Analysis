{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\DataScience\\\\Projects\\\\Text_analysis\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\DataScience\\\\Projects\\\\Text_analysis'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TextProcessingConfig:\n",
    "    root_dir: Path\n",
    "    stop_words_folder_path: Path\n",
    "    processed_text_path: Path\n",
    "    merged_stop_words_path: Path\n",
    "    extracted_files_folder_path: Path\n",
    "    destination_folder: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.text_analysis.constants import *\n",
    "from src.text_analysis.utils.common import read_yaml_file, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml_file(config_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_text_processing_config(self) -> TextProcessingConfig:\n",
    "        config = self.config.text_processing\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = TextProcessingConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            stop_words_folder_path=config.stop_words_folder_path,\n",
    "            processed_text_path=config.processed_text_path,\n",
    "            merged_stop_words_path=config.merged_stop_words_path,\n",
    "            extracted_files_folder_path=config.extracted_files_folder_path,\n",
    "            destination_folder=config.destination_folder,\n",
    "        )\n",
    "\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessing:\n",
    "    def __init__(self, config: TextProcessingConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def merge_stop_words_files(self):\n",
    "        folder_path=self.config.stop_words_folder_path\n",
    "        print(folder_path)\n",
    "        merged_file_path=os.path.join(self.config.merged_stop_words_path,\"StopWords\")\n",
    "        os.makedirs(merged_file_path, exist_ok=True)\n",
    "        print(merged_file_path)\n",
    "        unwanted_pattern = re.compile(r\"(http[s]?://|www\\.)|Surnames from 1990 census|census\\.gov\")\n",
    "\n",
    "        print(os.listdir(folder_path))        \n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path=os.path.join(folder_path,filename)\n",
    "\n",
    "            if os.path.isfile(file_path):\n",
    "                with open(file_path,\"r\",encoding=\"ISO-8859-1\") as file:\n",
    "                    lines = file.readlines()\n",
    "\n",
    "                # Process each line to extract the relevant content\n",
    "                new_lines = []\n",
    "                for line in lines:\n",
    "                    if unwanted_pattern.search(line):\n",
    "                        continue\n",
    "\n",
    "                    if '|' in line:\n",
    "                        # Split by '|', strip whitespace, and remove text in parentheses\n",
    "                        parts = [re.sub(r'\\s*\\(.*?\\)\\s*', '', part).strip() for part in line.split('|')]\n",
    "                        # Add each part as a separate line in the new format\n",
    "                        new_lines.append(parts[0] + '\\n' + parts[1] + '\\n')\n",
    "                    else:\n",
    "                        # If no '|' separator, add the line as it is\n",
    "                        new_lines.append(line)\n",
    "\n",
    "        # Write the modified content back to the same file\n",
    "        merged_file_path = os.path.join(merged_file_path, filename)\n",
    "        with open(merged_file_path, \"w\", encoding=\"ISO-8859-1\") as file:\n",
    "                file.writelines(new_lines)\n",
    "                \n",
    "    \n",
    "    def process_text(self):\n",
    "        folder_path=self.config.extracted_files_folder_path\n",
    "        for filename in os.listdir(folder_path):\n",
    "            \n",
    "            file_path=os.path.join(folder_path,filename)\n",
    "            \n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "            \n",
    "            content_start = text.find('==================================================\\n\\n')\n",
    "            if content_start != -1:\n",
    "                text = text[content_start + 51:]\n",
    "                \n",
    "            # text=text[1:]\n",
    "            \n",
    "            text=re.sub(r\"[^a-zA-Z\\s]\",\"\",text)\n",
    "            text=text.lower()\n",
    "            lines = text.splitlines()\n",
    "            lines = [line for line in lines if line.strip()]\n",
    "            text = \"\\n\".join(lines)\n",
    "            \n",
    "            file_path=os.path.join(self.config.processed_text_path,filename)\n",
    "            with open(file_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-14 18:47:18,987: INFO:common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2024-11-14 18:47:18,987: INFO:common: createD Directory at:artifacts]\n",
      "[2024-11-14 18:47:18,987: INFO:common: createD Directory at:artifacts/text_processing]\n",
      "assets/StopWords\n",
      "artifacts/text_processing\\StopWords\n",
      "['StopWords_Auditor.txt', 'StopWords_Currencies.txt', 'StopWords_DatesandNumbers.txt', 'StopWords_Generic.txt', 'StopWords_GenericLong.txt', 'StopWords_Geographic.txt', 'StopWords_Names.txt']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    text_processing_config = config.get_text_processing_config()\n",
    "    text_processing = TextProcessing(config=text_processing_config)\n",
    "    text_processing.merge_stop_words_files()\n",
    "    text_processing.process_text()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envTA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
